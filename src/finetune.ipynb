{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import os\n",
    "import json\n",
    "from datasets import Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_folder(folder_path):\n",
    "    data_files = os.listdir(folder_path)\n",
    "    data = []\n",
    "    for file_name in data_files:\n",
    "        if file_name.lower().endswith('.json'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                item = json.load(file)\n",
    "                data.append(item)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = os.path.join(\"..\", \"syllabuses\")\n",
    "data = load_data_from_folder(folder_path)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_course_data(data):\n",
    "    def process(x):\n",
    "        if (x.get('Title') and x.get('Short Description') and x.get('Course Topics') and\n",
    "            x.get('Intended Learning Outcomes (ILOs)') and x.get('Formative Assessment and Course Activities')\n",
    "           ):\n",
    "            return ('Course title: ' + x.get('Title').strip()+'\\n'+'Course description: '+  x.get('Short Description').strip()+\n",
    "                    '\\n'+'Course topics: '+str(x.get('Course Topics'))\n",
    "                   +'Intended Learning Outcomes (ILOs): ' + str(x.get('Intended Learning Outcomes (ILOs)')) + '\\n'\n",
    "                   + 'Formative Assessment and Course Activities: ' + str(x.get('Formative Assessment and Course Activities')))\n",
    "        return None\n",
    "\n",
    "    return [process(x) for x in data if process(x)]\n",
    "\n",
    "data_proc = preprocess_course_data(data)\n",
    "dataset = Dataset.from_dict({\"text\": data_proc})\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetDict = dataset.train_test_split(train_size=0.8, shuffle=True, seed=42)\n",
    "train_dataset = datasetDict['train']\n",
    "eval_dataset = datasetDict['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define basic prompt for comparison between baseline & finetuned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_eval(model, tokenizer):\n",
    "    model_params = {\n",
    "        \"max_new_tokens\": 2048,\n",
    "    }\n",
    "    with open(\"prompt_template_finetune.txt\", \"r\", encoding='utf-8') as f:\n",
    "        prompt_base = f.read()\n",
    "    COURSE_NAME = \"Statistical Techniques For Data Science and Robotics\"\n",
    "    COURSE_DESCRIPTION = \"This advanced course covers main concepts in statics used in industry, including hypothesis testing, statistical tests, probabilitic and bayesian models.\"\n",
    "    prompt_str = f\"{prompt_base}\\nCourse title: {COURSE_NAME}\\nCourse description: {COURSE_DESCRIPTION}\\nCourse topics: \"\n",
    "    chat = [\n",
    "        { \"role\": \"user\", \"content\": prompt_str},\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "    input_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=input_ids.cuda(),\n",
    "        **model_params,\n",
    "    )\n",
    "    response = tokenizer.decode(generated_ids[0])\n",
    "    return response[len(prompt):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistral-7B-v0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "45524c98039a46d5b7745ad7cb638d2f"
     ]
    },
    "id": "E0Nl5mWL0k2T",
    "outputId": "47b6b01d-e9f2-4b70-919c-17ae64993843"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4d840a0c164bdb8b8c48f85098e1e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also try gemma 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_TOKEN'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87ca10eb94a401eb526d639e7a0218a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"google/gemma-1.1-2b-it\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "haSUDD9HyRgf",
    "outputId": "22ee95db-2974-4ab0-e0c7-444d04d3e838"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(prompt['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample check on baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sample_eval(model, tokenizer)\n",
    "with open('gemma-2b-it-baseline-answer.txt', 'w') as f:\n",
    "    f.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Course Title\": \"Statistical Techniques For Data Science and Robotics\",\n",
      "    \"Course Description\": \"This course provides an advanced understanding of statistical techniques used in data science and robotics. Topics include hypothesis testing, statistical tests, probability and Bayesian models, and their applications in data science and robotics.\"\n",
      "    ,\n",
      "    \"Sections\": [\n",
      "        {\n",
      "            \"Section\": \"Hypothesis Testing and Statistical Inference\",\n",
      "            \"Topics\": [\n",
      "                \"Introduction to hypothesis testing\",\n",
      "                \"Statistical inference\",\n",
      "                \"Hypothesis testing procedures\",\n",
      "                \"Confidence intervals\",\n",
      "                \"Hypothesis testing in robotics\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Section\": \"Statistical Tests and Probability Models\",\n",
      "            \"Topics\": [\n",
      "                \"Statistical tests for normality\",\n",
      "                \"Statistical tests for independence\",\n",
      "                \"Statistical tests for equality of variances\",\n",
      "                \"Bayesian models for probabilistic reasoning\",\n",
      "                \"Bayesian networks for decision making\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Section\": \"Advanced Statistical Techniques\",\n",
      "            \"Topics\": [\n",
      "                \"Generalized linear models\",\n",
      "                \"Logistic regression\",\n",
      "                \"Decision trees and ensemble methods\",\n",
      "                \"Bayesian networks\",\n",
      "                \"Deep learning\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Section\": \"Applications in Robotics\",\n",
      "            \"Topics\": [\n",
      "                \"Robotics sensor fusion\",\n",
      "                \"Robotics path planning\",\n",
      "                \"Robotics control\",\n",
      "                \"Robotics decision making\",\n",
      "                \"Robotics evaluation\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```<eos>\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization & preparation continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "S3iLAwLh3m19"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43868bcb742b4266a7bb8d4d23e93a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a482231b7e94bfe94333ed500d15dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_eval_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BA8M9yfC3m19",
    "outputId": "99c6d302-9bb6-47b1-cae9-a1cd870b4770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "acINaViR3m19"
   },
   "outputs": [],
   "source": [
    "max_length = 512 # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(prompt):\n",
    "    result = tokenizer(\n",
    "        prompt['text'],\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "518d4f0b89bf4d57bf00d4c6d6e59eb5"
     ]
    },
    "id": "lTk-aTog3m19",
    "outputId": "4fb637b4-77a2-47c6-de7b-4fb620663dd7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49008f4b980b4f05bb82c803aa7ab239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc900fab4444f10b027a25b9322319e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
    "tokenized_eval_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OKHhvxK83m19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 15108, 4680, 235292, 10732, 1887, 13403, 14715, 108, 15108, 5966, 235292, 1417, 3205, 14979, 573, 2412, 17482, 235292, 13403, 6044, 167181, 235289, 13403, 14715, 17210, 235269, 578, 28514, 235265, 108, 15108, 16254, 235292, 20411, 235303, 10437, 2130, 777, 8437, 9470, 14715, 920, 777, 47921, 2819, 573, 4337, 2130, 7999, 5587, 577, 13403, 14715, 920, 777, 86604, 5034, 578, 8449, 9874, 920, 777, 1510, 2769, 235290, 26347, 920, 777, 18409, 60350, 920, 777, 31435, 24429, 60350, 920, 777, 44833, 153896, 920, 777, 167433, 60350, 920, 777, 79111, 235290, 1155, 985, 532, 14150, 2672, 920, 777, 62419, 1865, 17283, 578, 26221, 920, 777, 184707, 60350, 920, 777, 200406, 124047, 920, 777, 235333, 11426, 920, 777, 176063, 81054, 920, 777, 26300, 81054, 920, 777, 29144, 2465, 920, 777, 38954, 19185, 19609, 31198, 920, 777, 2923, 2928, 4342, 14715, 40791, 920, 777, 5524, 235290, 23513, 31198, 920, 777, 12190, 13429, 56148, 920, 777, 124816, 36338, 920, 777, 44361, 103654, 10214, 13429, 56148, 920, 777, 48670, 82645, 2074, 789, 19276, 10437, 2130, 777, 53298, 41936, 578, 72683, 11026, 920, 777, 47921, 2819, 573, 4337, 2130, 7999, 53298, 41936, 920, 777, 17935, 3360, 920, 777, 63949, 574, 920, 777, 13020, 12533, 920, 777, 1441, 670, 9508, 2074, 789, 19276, 10437, 2130, 777, 18808, 55760, 9470, 14715, 920, 777, 47921, 2819, 573, 4337, 2130, 7999, 235333, 235290, 44544, 139802, 920, 777, 235333, 235290, 44544, 1641, 920, 777, 210261, 139802, 920, 777, 4994, 76707, 920, 777, 15097, 235290, 19494, 2074, 789, 19276, 10437, 2130, 777, 26843, 14715, 920, 777, 47921, 2819, 573, 4337, 2130, 7999, 105460, 57663, 37541, 920, 777, 3663, 235290, 141502, 920, 777, 185390, 492, 57663, 37541, 920, 777, 4122, 43723, 920, 777, 9680, 482, 8923, 6033, 43723, 920, 777, 3540, 1386, 2009, 1267, 3201, 492, 37541, 2074, 12765, 147884, 14715, 51829, 591, 2031, 13285, 1245, 19276, 1841, 603, 573, 1872, 6187, 576, 736, 3205, 235336, 2130, 777, 3493, 603, 476, 8547, 2567, 1476, 576, 9278, 30942, 575, 18225, 17273, 235269, 1423, 38186, 235269, 578, 6479, 6044, 235265, 11569, 235269, 573, 6187, 576, 736, 3205, 603, 577, 3658, 3787, 675, 671, 32713, 5158, 576, 476, 4972, 235290, 927, 576, 573, 2621, 6635, 576, 6479, 6044, 235269, 675, 671, 21629, 611, 32372, 1174, 575, 5354, 19991, 25411, 235269, 578, 2177, 1174, 577, 11560, 1879, 235290, 9097, 1423, 8042, 4552, 34763, 777, 2031, 13285, 6908, 696, 2149, 5902, 2130, 19276, 6982, 235248, 235274, 235292, 2439, 17482, 1412, 476, 5913, 1230, 235283, 44759, 235283, 113120, 235336, 2130, 7999, 46039, 6044, 167181, 920, 777, 235280, 5396, 8080, 576, 6044, 17210, 578, 28514, 920, 777, 17356, 6044, 8791, 920, 777, 26300, 30660, 920, 777, 36748, 6479, 6044, 6815, 8112, 7525, 777, 6982, 235248, 235284, 235292, 2439, 6859, 11572, 7841, 1412, 476, 5913, 614, 3326, 577, 3114, 235336, 2130, 7999, 62419, 1865, 2167, 6044, 167181, 920, 777, 62419, 1865, 17283, 578, 26221, 920, 777, 44629, 576, 6044, 7900, 591, 34585, 235283, 42659, 6082, 24781, 578, 2910, 40934, 3687, 2330, 920, 777, 48670, 5358, 920, 777, 29144, 2465, 920, 777, 144255, 14715, 920, 777, 127138, 689, 20555, 14715, 7525, 777, 6982, 235248, 235304, 1]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "a9EUEDAl0ss3"
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gkIcwsSU01EB"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XshGNsbxyRgj",
    "outputId": "c619b0e8-8516-4d4b-9abe-13eaa3f3b204",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GemmaForCausalLM(\n",
      "  (model): GemmaModel(\n",
      "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-17): 18 x GemmaDecoderLayer(\n",
      "        (self_attn): GemmaSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): GemmaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): GemmaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=16384, out_features=2048, bias=False)\n",
      "          (act_fn): PytorchGELUTanh()\n",
      "        )\n",
      "        (input_layernorm): GemmaRMSNorm()\n",
      "        (post_attention_layernorm): GemmaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): GemmaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Ybeyl20n3dYH",
    "outputId": "6a16c182-04d9-4812-ae81-502a8fe364d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 23740416 || all params: 1539008512 || trainable%: 1.5425786027101585\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "IaYMWak4yRgn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GemmaForCausalLM(\n",
      "      (model): GemmaModel(\n",
      "        (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
      "        (layers): ModuleList(\n",
      "          (0-17): 18 x GemmaDecoderLayer(\n",
      "            (self_attn): GemmaSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): GemmaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): GemmaMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=16384, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=16384, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=16384, out_features=2048, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=16384, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act_fn): PytorchGELUTanh()\n",
      "            )\n",
      "            (input_layernorm): GemmaRMSNorm()\n",
      "            (post_attention_layernorm): GemmaRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): GemmaRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=2048, out_features=256000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=2048, out_features=16, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=16, out_features=256000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jq0nX33BmfaC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrudakov/.local/share/virtualenvs/AML-Project-RNdI0Dn9/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mglemhel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mrudakov/study/AML-Project/src/wandb/run-20240417_160408-30asqw0e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/glemhel/syllabus-finetune/runs/30asqw0e' target=\"_blank\">laced-breeze-9</a></strong> to <a href='https://wandb.ai/glemhel/syllabus-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/glemhel/syllabus-finetune' target=\"_blank\">https://wandb.ai/glemhel/syllabus-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/glemhel/syllabus-finetune/runs/30asqw0e' target=\"_blank\">https://wandb.ai/glemhel/syllabus-finetune/runs/30asqw0e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrudakov/.local/share/virtualenvs/AML-Project-RNdI0Dn9/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:26, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.886800</td>\n",
       "      <td>2.388415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.123800</td>\n",
       "      <td>2.060828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.810300</td>\n",
       "      <td>1.991367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.703900</td>\n",
       "      <td>1.972193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.751300</td>\n",
       "      <td>1.968478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=2.0552300415039064, metrics={'train_runtime': 28.6572, 'train_samples_per_second': 4.362, 'train_steps_per_second': 4.362, 'total_flos': 770159935488000.0, 'train_loss': 2.0552300415039064, 'epoch': 2.6})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "output_dir = os.path.join('.', 'output')\n",
    "os.environ['WANDB_PROJECT'] = 'syllabus-finetune'\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=10,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=125,\n",
    "        learning_rate=2e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        # save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        # save_steps=25,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=False,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        # run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▃▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▁▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁████</td></tr><tr><td>eval/steps_per_second</td><td>▁████</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/grad_norm</td><td>█▃▄▁▂</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.96848</td></tr><tr><td>eval/runtime</td><td>0.5811</td></tr><tr><td>eval/samples_per_second</td><td>22.371</td></tr><tr><td>eval/steps_per_second</td><td>3.442</td></tr><tr><td>total_flos</td><td>770159935488000.0</td></tr><tr><td>train/epoch</td><td>2.6</td></tr><tr><td>train/global_step</td><td>125</td></tr><tr><td>train/grad_norm</td><td>4.80107</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7513</td></tr><tr><td>train_loss</td><td>2.05523</td></tr><tr><td>train_runtime</td><td>28.6572</td></tr><tr><td>train_samples_per_second</td><td>4.362</td></tr><tr><td>train_steps_per_second</td><td>4.362</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">laced-breeze-9</strong> at: <a href='https://wandb.ai/glemhel/syllabus-finetune/runs/30asqw0e' target=\"_blank\">https://wandb.ai/glemhel/syllabus-finetune/runs/30asqw0e</a><br/> View project at: <a href='https://wandb.ai/glemhel/syllabus-finetune' target=\"_blank\">https://wandb.ai/glemhel/syllabus-finetune</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240417_160408-30asqw0e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result after fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    result = sample_eval(model, tokenizer)\n",
    "    with open('gemma-2b-it-finetuned-answer.txt', 'w') as f:\n",
    "        f.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n    \"Section 1\": [\\n        \"Introduction to Statistical Techniques\",\\n        \"Hypothesis Testing\",\\n        \"Statistical Tests\",\\n        \"Probability Theory\",\\n        \"Bayesian Models\"\\n    ],\\n    \"Section 2\": [\\n        \"Statistical Tests\",\\n        \"Bayesian Models\",\\n        \"Hypothesis Testing\",\\n        \"Statistical Tests\",\\n        \"Bayesian Models\"\\n    ],\\n    \"Section 3\": [\\n        \"Statistical Tests\",\\n        \"Bayesian Models\",\\n        \"Hypothesis Testing\",\\n        \"Statistical Tests\",\\n        \"Bayesian Models\"\\n    ]\\n}\\n```<eos>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
