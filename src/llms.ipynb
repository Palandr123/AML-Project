{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrey/anaconda3/envs/aml_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from src.template import template_assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Model and tokenizer names{\n",
    "model_name = \"google/gemma-1.1-2b-it\" #\"mistralai/Mistral-7B-Instruct-v0.2\" #\"google/gemma-1.1-2b-it\" # #\"google/gemma-1.1-2b-it\" #\"google/gemma-7b-it\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "device = torch.device(\"cuda:1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).eval().to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"max_new_tokens\": 700,\n",
    "    #\"temperature\": 0.1,\n",
    "}\n",
    "COURSE_NAME = \"Big Data Technologies and Analytics\"#\"Advanced Machine Learning\"\n",
    "COURSE_DESCRIPTION = \"This course covers the following concepts: Advanced distributed data organization; Advanced distributed data processing.\" #\"\"This course covers the following concepts: Advanced topics in machine learning; To develop research interest in the theory and application of machine learning.\"\n",
    "PREREQUISITES = {\n",
    "    \"PREREQUISITE_SUBJECTS\": [],\n",
    "    \"PREREQUISITE_TOPICS\": []\n",
    "}\n",
    "# COURSE_TOPICS = [\n",
    "#         {\n",
    "#             \"Section\": \"Deep Learning Architectures and Optimization\",\n",
    "#             \"Topics within the section\": [\n",
    "#                 \"Convolutional Neural Networks\",\n",
    "#                 \"Autoencoders\",\n",
    "#                 \"Generative Adversarial Networks\",\n",
    "#                 \"Training Deep Learning Models\",\n",
    "#                 \"Optimization Techniques for Deep Learning\"\n",
    "#             ]\n",
    "#         },\n",
    "#         {\n",
    "#             \"Section\": \"Unsupervised Learning Techniques and Applications\",\n",
    "#             \"Topics within the section\": [\n",
    "#                 \"K-means Clustering\",\n",
    "#                 \"Hierarchical Clustering\",\n",
    "#                 \"Dimensionality Reduction Techniques\",\n",
    "#                 \"Anomaly Detection\",\n",
    "#                 \"Generative Adversarial Networks\"\n",
    "#             ]\n",
    "#         },\n",
    "#         {\n",
    "#             \"Section\": \"Large-Scale Machine Learning and Distributed Learning\",\n",
    "#             \"Topics within the section\": [\n",
    "#                 \"Distributed Training\",\n",
    "#                 \"Parallel Computing Frameworks\",\n",
    "#                 \"Scaling Machine Learning Models\",\n",
    "#                 \"Federated Learning\",\n",
    "#                 \"Local Outlier Detection\"\n",
    "#             ]\n",
    "#         },\n",
    "#         {\n",
    "#             \"Section\": \"Emerging Trends in Machine Learning\",\n",
    "#             \"Topics within the section\": [\n",
    "#                 \"Reinforcement Learning\",\n",
    "#                 \"Natural Language Processing\",\n",
    "#                 \"Generative Adversarial Networks\",\n",
    "#                 \"Diffusion Models\",\n",
    "#                 \"Bayesian Deep Learning\"\n",
    "#             ]\n",
    "#         }\n",
    "# ]\n",
    "COURSE_TOPICS = [\n",
    "    {\n",
    "      \"Section\": \"Introduction\",\n",
    "      \"Topics within the section\": [\n",
    "        \"What is Big Data\",\n",
    "        \"Characteristics of Big Data\",\n",
    "        \"Technologies\",\n",
    "        \"Virtualization and cloud computing\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"Section\": \"File systems and resource managers\",\n",
    "      \"Topics within the section\": [\n",
    "        \"HDFS\",\n",
    "        \"YARN\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"Section\": \"Batch Processing\",\n",
    "      \"Topics within the section\": [\n",
    "        \"Distributed batch processing\",\n",
    "        \"MapReduce model\",\n",
    "        \"Applications\",\n",
    "        \"Tasks management\",\n",
    "        \"Patterns\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"Section\": \"Stream Processing\",\n",
    "      \"Topics within the section\": [\n",
    "        \"CAP theorem\",\n",
    "        \"Distributed storage and computation\",\n",
    "        \"Distributed Stream Processing\",\n",
    "        \"Usage patterns\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"Section\": \"Analytics\",\n",
    "      \"Topics within the section\": [\n",
    "        \"Architecture\",\n",
    "        \"Use cases\",\n",
    "        \"SparkML\",\n",
    "        \"GraphX\"\n",
    "      ]\n",
    "    }\n",
    "]\n",
    "content = f\"{template_assessment}\\nCOURSE: {COURSE_NAME}\\nDESCRIPTION: {COURSE_DESCRIPTION}\\nCOURSE_TOPICS: {COURSE_TOPICS}\\nFINAL_ASSESSMENT:\"\n",
    "message = [ \n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": content,\n",
    "    },\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "        message, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "input_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "generated_ids = model.generate(\n",
    "    input_ids=input_ids.to(device),\n",
    "    **model_params,\n",
    ")\n",
    "response = tokenizer.decode(generated_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Sections\": [\n",
      "    {\n",
      "      \"Section\": \"Introduction\",\n",
      "      \"Topics within the section\": [\n",
      "        \"What is big data and its characteristics?\",\n",
      "        \"What are the technologies and tools used in big data analytics?\",\n",
      "        \"How does virtualization and cloud computing impact big data processing?\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Section\": \"File systems and resource managers\",\n",
      "      \"Topics within the section\": [\n",
      "        \"HDFS: Distributed file system for big data storage\",\n",
      "        \"YARN: Resource manager for big data processing\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Section\": \"Batch Processing\",\n",
      "      \"Topics within the section\": [\n",
      "        \"Distributed batch processing: Coordinating tasks across multiple nodes\",\n",
      "        \"MapReduce model: Programming paradigm for parallel processing of large datasets\",\n",
      "        \"Applications of batch processing in big data\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Section\": \"Stream Processing\",\n",
      "      \"Topics within the section\": [\n",
      "        \"CAP theorem: Scalable streaming data processing model\",\n",
      "        \"Distributed storage and computation: Handling high-throughput data streams\",\n",
      "        \"Distributed Stream Processing: Processing data in real-time\",\n",
      "        \"Usage patterns: Real-time analytics and streaming applications\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"Section\": \"Analytics\",\n",
      "      \"Topics within the section\": [\n",
      "        \"SparkML: Machine learning library for big data\",\n",
      "        \"GraphX: Graph processing library for big data\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}<eos>\n"
     ]
    }
   ],
   "source": [
    "print(response[len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m course_topics \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFINAL_ASSESSMENT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m start_index \u001b[38;5;241m=\u001b[39m course_topics\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m end_index \u001b[38;5;241m=\u001b[39m course_topics\u001b[38;5;241m.\u001b[39mrindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "course_topics = response[len(prompt):].split('\"FINAL_ASSESSMENT\": ')[1]\n",
    "start_index = course_topics.index(\"{\")\n",
    "end_index = course_topics.rindex(\"}\") + 1\n",
    "print(course_topics[start_index: end_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bd_gemma_assessment.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(f'{response[len(prompt):]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '{' on line 1 (<unknown>, line 28)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/aml_project/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[7], line 2\u001b[0m\n    res = {\"Final assessment\": ast.literal_eval(course_topics[start_index: end_index])}\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/aml_project/lib/python3.10/ast.py:64\u001b[0m in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/anaconda3/envs/aml_project/lib/python3.10/ast.py:50\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:28\u001b[0;36m\u001b[0m\n\u001b[0;31m    ]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '{' on line 1\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "res = {\"Final assessment\": ast.literal_eval(course_topics[start_index: end_index])}\n",
    "import json\n",
    "with open('aml_gemma_assessment.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(res, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
